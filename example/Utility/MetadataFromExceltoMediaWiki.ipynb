{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfd7cb0c-a1f0-4c82-af31-61ff3c7e91bd",
   "metadata": {},
   "source": [
    "# Purpose: Convert SST-1 Sample Sheet Metadata to MediaWiki Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171c8294-ffce-4373-b842-c068edf3a96d",
   "metadata": {},
   "source": [
    "## Imports and File Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80a91496-0a36-4ca6-8379-796aee6352c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import date\n",
    "import openpyxl\n",
    "\n",
    "# Import  Spreadsheet Reformat function\n",
    "from rsoxs_scans.spreadsheets import convertSampleSheetExcelMediaWiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96f694d0-efa0-4ce4-a87d-da95ed78145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide path to excel sheet\n",
    "# Ex: r'/nsls2/users/bpatel/Sample_Bar_template_v2022_11_beta_2_BPSuggestion.xlsx'\n",
    "excelSheetInputPath = Path(\"../Sample_Bar_v2023_2.xlsx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285215f0-948c-4e3e-8a97-df4196200437",
   "metadata": {},
   "source": [
    "## Function to Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d28e76d-17a0-4e2a-9139-90c61dd839c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertSampleSheetExcelMediaWiki(\n",
    "    excelSheet: Path = None,\n",
    "    paramsSheetToOutput: str = \"all\",\n",
    "    rulesSheetName: str = \"SheetRulesAndMetaData\",\n",
    "    versionCell: str = \"B4\",\n",
    "    startRow_Params: int = 7,\n",
    "    endRow_Params: int = None,\n",
    "    startColumn_Params: str = \"A\",\n",
    "    endColumn_Params: str = \"F\",\n",
    "    verbose: bool = \"TRUE\",\n",
    ") -> str:\n",
    "    \"\"\"Converts Sample Sheet Parameter Metadata into a MediaWiki-compatible format string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    excelSheet: Path\n",
    "        Path (or string) to the excel sheet to be loaded.\n",
    "    rulesSheetName: str\n",
    "        Name of the excel sheet which should be parsed for metadata\n",
    "    paramsSheetToOutput: str\n",
    "        Which set of params should be output (e.g., 'bar', 'acquisitions'). 'all' will sequentially output tables for the same wiki page\n",
    "    versionCell: str\n",
    "        Location (e.g., 'B4') of the cell that contains the sheet version number\n",
    "    startRow_Params: int\n",
    "        Excel row number which contains the header for the metadata table (excel starts at row 1)\n",
    "    endRow_Params: int\n",
    "        Excel row number which contains the last row of metadata (leave as -1 if scanning to end of file)\n",
    "    startColumn_Params: str\n",
    "        First excel column (by letter) that contains the metadata table\n",
    "    endColumn_Params:str\n",
    "        Last excel column (by letter) that contains the metadata table\n",
    "    verbose: bool\n",
    "        Whether to print progress text to stdout\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A string containing the formatted table ready to copy-paste into MediaWiki\n",
    "    \"\"\"\n",
    "\n",
    "    if verbose:\n",
    "        print(\"-\" * 5 + \" Start Log\" + \"-\" * 5)\n",
    "        print(\"\\tExtracting Sheet Version...\", end=\" \")\n",
    "\n",
    "    # Step 1: Extract Version Cell and add to wiki table header\n",
    "    ## Split versionCell in (row, column)\n",
    "    versRow, versColumn = [\n",
    "        int(\"\".join(filter(str.isdigit, versionCell))),\n",
    "        \"\".join(filter(str.isalpha, versionCell)),\n",
    "    ]\n",
    "\n",
    "    ## Extract Version Code as a string\n",
    "    versionStr = openpyxl.load_workbook(excelSheet).properties.title\n",
    "    # print(versionStr)\n",
    "\n",
    "    ## Get Current Date\n",
    "    date.today()\n",
    "\n",
    "    ## Add Wiki Page Header to Output string\n",
    "    outStr = (\n",
    "        f\"== SST-1 Sample Sheet Syntax Version: {versionStr} Last Updated: {date.today()} ==\\n\"\n",
    "    )\n",
    "    if verbose:\n",
    "        print(f\"Pass!\\n\\t\\tVersion Number is -> {versionStr}\")\n",
    "\n",
    "    # Step 2: Extract Metadata Table from Excel Sheet\n",
    "    if verbose:\n",
    "        print(\"\\tExtracting Sheet Metadata...\")\n",
    "\n",
    "    ## If endRow_Params is provided, limit the number of rows parsed\n",
    "    if endRow_Params is None:\n",
    "        numRows = None\n",
    "    else:\n",
    "        numRows = endRow_Params - startRow_Params\n",
    "\n",
    "    ## Convert column bounds to string\n",
    "    colString = startColumn_Params + \":\" + endColumn_Params\n",
    "\n",
    "    excelMetadataIn = pd.read_excel(\n",
    "        excelSheet,\n",
    "        sheet_name=rulesSheetName,\n",
    "        header=startRow_Params - 1,\n",
    "        nrows=numRows,\n",
    "        usecols=colString,\n",
    "    )\n",
    "\n",
    "    ## Drop empty rows (where 'Sheet' is NaN)\n",
    "    excelMetadataIn = excelMetadataIn.dropna(subset=\"Sheet\")\n",
    "    ## Replace NaNs and 'nan's with blank\n",
    "    excelMetadataIn = excelMetadataIn.replace(\"nan\", \"\")\n",
    "    excelMetadataIn = excelMetadataIn.fillna(\" \")\n",
    "\n",
    "    ###display(excelMetadataIn)\n",
    "\n",
    "    ## Build MediaWiki Tables\n",
    "\n",
    "    ## Get list of unique sheets for which we have metadata\n",
    "    sheetList = excelMetadataIn.Sheet.unique()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\t\\tFound Metadata for these sheets: {sheetList}\")\n",
    "        print(f\"\\t\\tUser requested tables for: {paramsSheetToOutput}\")\n",
    "\n",
    "    # Filter down the list of tables to output\n",
    "    if paramsSheetToOutput.lower() == \"all\":\n",
    "        sheetListToRun = sheetList\n",
    "    else:\n",
    "        sheetListToRun = [paramsSheetToOutput]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\t\\tOutputting tables for: {sheetListToRun}...\")\n",
    "\n",
    "    # Create subset dataframes\n",
    "    dataframeList = []\n",
    "    for sheetName in sheetListToRun:\n",
    "        dataframeList.append(excelMetadataIn[excelMetadataIn.Sheet == sheetName])\n",
    "\n",
    "    ###print(dataframeList[1])\n",
    "\n",
    "    ## Make one table per value in the 'Sheet' column\n",
    "    for excelMetadataFrame in dataframeList:\n",
    "        excelMetadataFrame.reset_index(drop=True, inplace=True)\n",
    "        outStr += \"\\n\" + r'{| class=\"wikitable sortable\"' + \"\\n\" + \"|-\\n\"\n",
    "\n",
    "        # Add header row elements\n",
    "        outStr += \"! \"\n",
    "        for colHeader in excelMetadataFrame.columns:\n",
    "            filteredColHeader = str(colHeader).replace(\"\\r\", \" \").replace(\"\\n\", \" \")\n",
    "            outStr += f\"{filteredColHeader} !! \"\n",
    "\n",
    "        # trim extra \"!! \"\n",
    "        outStr = outStr[:-4]\n",
    "\n",
    "        ###display(excelMetadataFrame)\n",
    "\n",
    "        # Add Metadata Row Elements\n",
    "\n",
    "        ## Loop through metadata rows\n",
    "        for mdRow in excelMetadataFrame.index:\n",
    "            ###Loop through columns\n",
    "            outStr += \"\\n|-\\n| \"\n",
    "            ###print(mdRow)\n",
    "            for mdVal in excelMetadataFrame.iloc[mdRow].to_list():\n",
    "                filteredmdVal = str(mdVal).replace(\"\\r\", \" \").replace(\"\\n\", \" \")\n",
    "                outStr += f\"{filteredmdVal} || \"\n",
    "                ###print(f\"\\t{mdVal}\")\n",
    "            # trim extra \" || \" at the end of each line\n",
    "            outStr = outStr[:-4]\n",
    "\n",
    "        # Add MediaWiki Table End\n",
    "        outStr += \"\\n|}\\n\"\n",
    "        # print(outStr)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"-\" * 5 + \" End Log. Copy text below this line into the wiki\" + \"-\" * 5)\n",
    "\n",
    "    return outStr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9db714-6db7-4dbb-9a77-51c257b280e5",
   "metadata": {},
   "source": [
    "## Example Usage: All Tables in one Wiki Page\n",
    "\n",
    "https://wiki-nsls2.bnl.gov/beamline7ID1/index.php?title=User:Bijal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dabcf3fc-035e-4100-b26b-b443a56da39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== SST-1 Sample Sheet Syntax Version: 2023-2 Version 1.0 Last Updated: 2023-08-09 ==\n",
      "\n",
      "{| class=\"wikitable sortable\"\n",
      "|-\n",
      "! Sheet !! Parameter !! Description !! Rules !! Example !! Notes\n",
      "|-\n",
      "| Bar || bar_name || REQUIRED: Unique name for this bar || Type: String All rows in the sheet must contain the same value for bar_name. || testbar ||  \n",
      "|-\n",
      "| Bar || sample_id || REQUIRED: Unique identifier for the sample.  || Type: String Must match any physical sample labels. All rows must have unique sample_id. || EG01 || This is what will be referenced in the acquisitions, so keep it reasonably short. Recommend to stick to letter,numbers, and underscore.\n",
      "|-\n",
      "| Bar || sample_name || REQUIRED: Identifier for the sample (can be non-unique) || Type: String Plain english is encouraged || P3HT-AN-120C || Will be in file name (readable by whoever is loading and measuring samples)\n",
      "|-\n",
      "| Bar || project_name || REQUIRED: Used as the name of the output data folder. || Type: String Any characters allowed on a linux filesystem || NEXAFS or RSoXS or OPVs or lastName || The largest degree of sample classification.\n",
      "|-\n",
      "| Bar || institution || REQUIRED: Short abbreviation of your institution that will be added to folder names.   || Type: String Be consistent across all beamtimes || NIST or NCSU or UPENN ||  \n",
      "|-\n",
      "| Bar || proposal_id || REQUIRED: 6-digit proposal number for this measurement.   || Type: int This must match the approved proposal for this beamtime. Only include the numeric part. || 310704 || In PASS, General user proposals generally begin with GU- and contain 6 digits.\n",
      "|-\n",
      "| Bar || bar_spot || REQUIRED: Location on the bar that you loaded the sample (within rows 1-27 and columns A-D). This will be used during alignment, so be careful! || Type: String Sample loading convention must match the wiki page 'RSoXS Sample Prep Advice' (link in the Notes for this parameter). || 1A OR 12CD OR third sample from top, blue and shiny || The program will display this text when you are identifying the samples in the bar image.  See https://wiki-nsls2.bnl.gov/beamline7ID1/index.php?title=RSoXS_Sample_Prep_Advice for bar orientation help.\n",
      "|-\n",
      "| Bar || front || REQUIRED: Is the sample mounted on the flat side of the bar (front)? || Type: boolean TRUE OR FALSE || True ||  \n",
      "|-\n",
      "| Bar || grazing || REQUIRED: Is this sample to be measured in grazing geometry (i.e., will it stop X-ray transmission?). || Type: boolean TRUE or FALSE || True || For Transmission RSoXS, this should be TRUE For TEY NEXAFS, this should be FALSE\n",
      "|-\n",
      "| Bar || angle || REQUIRED: Incident angle at which to collect data by default. This parameter is overwritten by acquisition plans that specify specific angles or angle series.  || Type: int or float  If grazing TRUE:  0 is parallel to the surface. Valid angles: 20 to 90 degrees. If grazing FALSE: 0 is perpendicular to the back surface. Valid angles: -14 to 90 degrees. || for transmission: 0 OR -1.6 for grazing: 30 OR 40 OR 55 || The lowest 'safe' value for grazing measurements is 30 degrees. \n",
      "|-\n",
      "| Bar || height || REQUIRED Distance from the surface of the sample bar to the top of the sample. || Type: int or float Value in mm. || 0.25 || Si Wafers are usually 250 microns thick (0.25 mm)\n",
      "|-\n",
      "| Bar || sample_desc || Full text description of your sample.  This will all be searchable in the database. || Type: String Any characters allowed on a linux filesystem || something about the sample default: \"\" ||  \n",
      "|-\n",
      "| Bar || project_desc || Extra information about the project || Type: String Any characters allowed on a linux filesystem || study of x effect on y default: \"\" ||  \n",
      "|-\n",
      "| Bar || sample_priority ||  REQUIRED 0 - critical  100-optional  This can be used for organizing the acquisition order of the bar || Type: int number between 0 and 100 || 1 || Optional sorting method for queue creation. See https://wiki-nsls2.bnl.gov/beamline7ID1/index.php?title=Guide_to_Acquisition_Sorting_Options for details.\n",
      "|-\n",
      "| Bar || notes || Any additional information about the sample or scans. Anything entered here will be searchable later in the database. || Type: String Any characters allowed on a linux filesystem || As-cast film for negative control of processing condition X. Needs C,F, O edge RSoXS. default: \"\" || Just an an additional metadata column.\n",
      "|-\n",
      "| Bar || sample_set || Sub-project grouping can help to sort data || Type: String Any characters allowed on a linux filesystem || opvs default: \"\" || Just an an additional metadata column.\n",
      "|-\n",
      "| Bar || components || List of components || Type: String Any characters allowed on a linux filesystem || p3ht default: \"\" || Useful for seaching for similar samples taken previously\n",
      "|-\n",
      "| Bar || composition || Quantitative composition, such as chemical formula for NEXAFS analysis || Type: String Should match a chemical formula || C1234H342O2F65 default: \"\" || Can be imported directly in QANT for Kramers Kronig\n",
      "|-\n",
      "| Bar || thickness || Thickness of sample for absorption quantification || Type: int or float Value in nm. || 125 default: \"\" || Can be imported directly in QANT for Kramers Kronig\n",
      "|-\n",
      "| Bar || density || Density of sample for absorption quantification || Type: int or float Value in g/mL || 1.05 default: \"\" || Can be imported directly in QANT for Kramers Kronig\n",
      "|-\n",
      "| Bar || sample_date || Date when sample was created || Type: String || 2022-03-09 default: \"\" ||  \n",
      "|-\n",
      "| Bar || location || AUTOGENERATED: Motor positions for sample (overwritten by rotations) || Autogenerated by beamline code - don't edit || Autogenerated by beamline code - don't edit || Autogenerated by beamline code - don't edit\n",
      "|-\n",
      "| Bar || bar_loc || AUTOGENERATED: Persistent sample positions, image positions, offsets, and fiducial positions || Autogenerated by beamline code - don't edit || Autogenerated by beamline code - don't edit || Autogenerated by beamline code - don't edit\n",
      "|-\n",
      "| Bar || proposal || AUTOGENERATED: Full detail on proposal || Autogenerated by beamline code - don't edit || Autogenerated by beamline code - don't edit || Autogenerated by beamline code - don't edit\n",
      "|-\n",
      "| Bar || SAF || AUTOGENERATED: Full details on the SAF || Autogenerated by beamline code - don't edit || Autogenerated by beamline code - don't edit || Autogenerated by beamline code - don't edit\n",
      "|-\n",
      "| Bar || analysis_dir || AUTOGENERATED: Directory where data is written out. || Autogenerated by beamline code - don't edit || Autogenerated by beamline code - don't edit || Autogenerated by beamline code - don't edit\n",
      "|-\n",
      "| Bar || data_session || AUTOGENERATED: || Autogenerated by beamline code - don't edit || Autogenerated by beamline code - don't edit || Autogenerated by beamline code - don't edit\n",
      "|-\n",
      "| Bar || acq_history || AUTOGENERATED: Full history of acquisitions performed on this sample || Autogenerated by beamline code - don't edit || Autogenerated by beamline code - don't edit || Autogenerated by beamline code - don't edit\n",
      "|-\n",
      "| Bar || RSoXS_Main_DET || AUTOGENERATED: Active Detector || Autogenerated by beamline code - don't edit || Autogenerated by beamline code - don't edit || Autogenerated by beamline code - don't edit\n",
      "|}\n",
      "\n",
      "{| class=\"wikitable sortable\"\n",
      "|-\n",
      "! Sheet !! Parameter !! Description !! Rules !! Example !! Notes\n",
      "|-\n",
      "| Acquisitions || sample_id || REQUIRED: identifies sample on which to run this acquisition || Type: String  Must exactly match a sample_id from the Bar sheet || EG01 ||  \n",
      "|-\n",
      "| Acquisitions || configuration || REQUIRED: Measurement Configuration || Type: String SAXS OR WAXS OR SAXSNEXAFS OR SAXS_liquid OR WAXS_liquid || SAXS || Determines which detector and slits are used.\n",
      "|-\n",
      "| Acquisitions || type || REQUIRED: Type of measurement || Type: String RSoXS OR NEXAFS OR Spiral || Spiral || Depending on the value of this cell, unnecessary acquisition parameters will be greyed out and locked. \n",
      "|-\n",
      "| Acquisitions || priority || REQUIRED: Determines which order scans will be run, lowest value first. || Type: int Valid Range: 1 to 100 || 2 default: 50 || Normal way to sort queue steps\n",
      "|-\n",
      "| Acquisitions || edge || REQUIRED: Which elemental edge or energy ranges you wish to scan. || Type: String, int, float, list Must match an entry in the lookup table (see Notes), OR be a single energy OR be a list of energies within hard brackets || carbon OR oxygen OR 285 OR [270,280,290,400] || See https://wiki-nsls2.bnl.gov/beamline7ID1/index.php?title=RSoXS_Acquisitions for details.\n",
      "|-\n",
      "| Acquisitions || ratios || The ratio of speed (NEXAFS) or density of energy steps (RSoXS) between the different energy intervals specified by the \"edge\" parameter || Type: String or list Must match the number of energy intervals specified by edge.  || carbon OR carbon nonaromatic OR [N, 1, N]  -> N times faster (NEXAFS), or take N times fewer energy measurements (RSoXS) in the 1st and 3rd intervals versus the 2nd. default: see wiki ||  See https://wiki-nsls2.bnl.gov/beamline7ID1/index.php?title=RSoXS_Acquisitions for details.\n",
      "|-\n",
      "| Acquisitions || frames || How many steps you want per energy scan || Type: String or int This is only an estimate, the threshold energies will always be favored.  || full or short or very short  default: full ||  See the examples in the rsoxs_scans\\example jupyter notebook, and run dry runs there to see actual numbers of exposures and experimental times\n",
      "|-\n",
      "| Acquisitions || repeats || How many images you want per energy step.   || Type: int || 5 default: 1 || Repeating exposures at a single step has much less overhead than defining multiple steps at one energy (~1 second vs  ~4 seconds)\n",
      "|-\n",
      "| Acquisitions || speed || Rate (eV/sec) to scan during NEXAFS. || Type: String or int || fast OR 0.3 OR 0.1  default: normal || Built in speeds are good starting points. 0.1 is slow (5 minutes or so for a scan)  0.3 is fast (<2 minutes / scan)\n",
      "|-\n",
      "| Acquisitions || cycles || How many times to sweep energy up and back down || Type:  int || 0, 1, 2 || For just one scan (low to high energy), use 0\n",
      "|-\n",
      "| Acquisitions || diameter || Diameter (mm) of spiral scan extent. || Type: int || 1.5 default: 1.8 ||  \n",
      "|-\n",
      "| Acquisitions || spiral_step || Distance (mm) between spiral scan steps. || Type: int || 0.5 default: 0.3 ||  \n",
      "|-\n",
      "| Acquisitions || pol_mode || Determines polarization convention for TEY NEXAFS measurements. See Notes. || Type: String  'sample' OR 'lab' || lab default: sample || Sample Frame: Fixed sample rotation at angle in angles. Specify polarization angle you want at the sample and the software will calculate the required beam polarization, while keeping the incident angle (beam footprint) constant. Laboratory Frame: You specify both beam polarization and sample rotation.\n",
      "|-\n",
      "| Acquisitions || polarizations || Polarization (pol) angles to take the measurements at.     || Type: int, list Any mode: -1, 0.5 -> clockwise, counter-clockwise circular pol RSoXS, Spiral, or NEXAFS pol_mode = lab -> 0-90 deg linear pol 0 deg: beam pol horizontal  w.r.t  instrument  90 deg: beam pol vertical w.r.t  instrument  NEXAFS pol_mode = sample -> 20-90 deg 0 deg : sample-relative pol normal to the sample surface 90 deg : sample-relative pol parallel to the sample surface.  || [30,55,70,90] for TEY NEXAFS series when angles = 30 0 for Magic angle TEY measurement, where angles = 55 -1, 0, 45, 90 for RSoXS at four beam polarizations default: 0 || For lab frame: 'horizontal' means along the in-board/outboard direction, and 'vertical' means along the up-down direction. For sample frame: 'sample_polarization' in the metadata will have the polarization at the sample, while 'polarization' will be the calculated beam polarization.\n",
      "|-\n",
      "| Acquisitions || angles || Angles for rotation of the sample about the vertical axis (theta)  Coordinate system matches that chosen on the 'Bar' sheet based on the values of parameters 'grazing' and 'angle' || Type: int or float or list Follow the rules for bar -> angle || 20,40,55,70,90 default: saved position || Note: This should only be filled in if you are deliberately changing the angle to be different from the one on the 'bar' sheet for an angle-scan series.   If you have picked the spiral position at an angle already, leave this blank or you may misalign your samples.\n",
      "|-\n",
      "| Acquisitions || exposure_time || Exposure time(s) in seconds for rsoxs scans and spirals || Type: int, list For rsoxs scans, a more complex nomenclature is available to define exposures for certain energy ranges. See the notebook example or the wiki.  || 0.01, 0.1, 1, 5 ,10 default: 1 ||  See https://wiki-nsls2.bnl.gov/beamline7ID1/index.php?title=RSoXS_Acquisitions for details.\n",
      "|-\n",
      "| Acquisitions || temperatures || temperature(s) to move to between / during scans.  || repeat the scans above for each temperature. || 120 || ONLY used with the TEM holder - not valid for normal sample bar\n",
      "|-\n",
      "| Acquisitions || temp ramp speed || the temperature ramp speed deg C / min ||  0.1 - 100 are valid speeds || 10 || ONLY used with the TEM holder - not valid for normal sample bar\n",
      "|-\n",
      "| Acquisitions || wait at temperature || wait for the temperature to reach the setpoint before starting the scans or not || True/False || True || ONLY used with the TEM holder - not valid for normal sample bar\n",
      "|-\n",
      "| Acquisitions || grating || which grating to use for measurements  || rsoxs (default), 1200, 250 || rsoxs || WARNING - moving gratings between measurements might result in loss of energy calibration\n",
      "|-\n",
      "| Acquisitions || diode_range || high or low range for diode measurements || high, low || high default: high || high should be used in any case where saturation might be a possibility - the majority of measurements\n",
      "|-\n",
      "| Acquisitions || slack_message_start || a message to send to the instrument-status channel of sst1-rsoxs-instrument Slack when this acquisition starts || Type: String Any characters allowed on a linux filesystem || Hey Eliot, I'm starting this important scan now ||  Add tagging to get notifications by finding your member ID from your slack profile page on the sst1-rsoxs-instrument.slack.com Slack Workspace and adding it like <@memberid>\n",
      "|-\n",
      "| Acquisitions || slack_message_end || a message to send to the RSoXS slack channel when this acquisition is finished || Type: String Any characters allowed on a linux filesystem || Done with this really important scan, start looking at the data! ||  Add tagging to get notifications by finding your member ID from your slack profile page on the sst1-rsoxs-instrument.slack.com Slack Workspace and adding it like <@memberid>\n",
      "|-\n",
      "| Acquisitions || group || a filter when \"run_bar\" is used, to only run certain acquisitions, and ignore others || string or number.  \"all\" or not specifying will mean this acquisition will run with any grouping.  Not specifying a group= in run_bar command will run all samples no matter their group || \"spirals\" || use to separate alignment scans which must all be run and analyzed before running data, or running ONLY some sub set of data.  This isn't sorting like priority, it's filtering\n",
      "|-\n",
      "| Acquisitions || acquisition_notes || plain English description of this scan  || Type: String Any characters allowed on a linux filesystem || carbon edge scan at three polarizations || Searchable in the database\n",
      "|}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(convertSampleSheetExcelMediaWiki(excelSheetInputPath, verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd5d28-000f-4bef-b6e9-f9214379cc9c",
   "metadata": {},
   "source": [
    "## Example Usage: Individual Tables for separate Wiki Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "01d0f280-b8f0-44f2-bd84-5b848c7cc991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== SST-1 Sample Sheet Syntax Version: 2023-1.1 Last Updated: 2023-01-06 ==\n",
      "\n",
      "{| class=\"wikitable sortable\"\n",
      "|-\n",
      "! Sheet !! Parameter !! Description !! Rules !! Example !! Notes\n",
      "|-\n",
      "| Acquisitions || sample_id || Must exactly match a sample_id from the Bar sheet ||   ||   ||  \n",
      "|-\n",
      "| Acquisitions || configuration || Measurement Configuration || Choose from WAXSNEXAFS, WAXS, SAXS, SAXSNEXAFS, SAXS_liquid, WAXS_liquid || SAXS || Determines which detector is used / slits\n",
      "|-\n",
      "| Acquisitions || type || Type of measurement || Choose from RSoXS, NEXAFS, Spiral || Spiral || Depending on the value of this cell, unnecessary acquisition parameters will be greyed out and locked. \n",
      "|-\n",
      "| Acquisitions || priority || Determines which order scans will be run, lowest value first. || Must be an integer from 1 to 100 || 2 || Normal way to sort queue steps\n",
      "|-\n",
      "| Acquisitions || edge || Which elemental edge or energy ranges you wish to scan. || Must match an entry in the lookup table (see Notes), OR be a single energy OR be a list of energies within hard brackets || carbon OR 285 OR [270,280,290,400] || Current Lookup table entries are given here [LINK]\n",
      "|-\n",
      "| Acquisitions || ratios || the ratio of resolution / speed between the different regions defined by the \"edge\" parameter || must match the number of regions defined by ratios. (length of ratios -1)  for built in ratio tables, look up the length needed || 5,1,5 -> go through the first and last region 5 times as fast (NEXAFS) or have the energy steps 5 times more spread out (RSoXS) than the central region  ||  \n",
      "|-\n",
      "| Acquisitions || frames || How many steps you want per energy scan (default 'full' which is 112 images, or specify the exact number you want) or how fast you want to run in ev/sec NEXAFS (default \"normal\" or 0.2), radius of the spiral (default 1.8) || this is only a estimate, the threshold energies will always be favored.  See the examples in the jupyter notebook, and run dry runs there to see actual numbers of exposures and experimental times || short ||  \n",
      "|-\n",
      "| Acquisitions || repeats || How many images you want per step.   || Repeating exposures at a single step has much less overhead ~1 second than defining multiple steps at one energy ~4 seconds || 5 -> repeat every exposure 5 times before moving to the next energy step' ||  \n",
      "|-\n",
      "| Acquisitions || speed || eV/sec to scan NEXAFS. || built in speeds are good starting points. 0.1 is slow (5 minutes or so for a scan)  0.3 is fast (<2 minutes / scan) || fast ||  \n",
      "|-\n",
      "| Acquisitions || cycles || how many times to sweep energy up and back down || any non negative integer || 0 -> no sweeping back down ||  \n",
      "|-\n",
      "| Acquisitions || diameter || diameter in mm of spiral scan extent ||   || 1.5 ||  \n",
      "|-\n",
      "| Acquisitions || spiral_step || step size for a spiral scan ||   || 0.3 ||  \n",
      "|-\n",
      "| Acquisitions || pol_mode || when specifying a polarization for a NEXAFS scan, wether the specification is relative to the sample surface or relative to the lab || in lab frame 0 is horizontal in board, 90 vertical up in sample frame, 0 is normal to the sample surface (minimum possible is the grazing angle of the sample), 90 is in the plane of the sample || 20 ||  \n",
      "|-\n",
      "| Acquisitions || polarizations || single angle or list of polarization angles to take measurement at || -1 -> circular -0.5 -> circular counter clockwise 0-180 -> angle from horizontal (sample frame: out of plane) through vertical (sample frame: in plane) || 20,30,55,70,90 ||  \n",
      "|-\n",
      "| Acquisitions || angles || angles for rotation of the sample about the vertical axis || number or list of numbers to take scans || 20,40,55,70,90 ||  \n",
      "|-\n",
      "| Acquisitions || exposure_time || exposure time(s) in seconds for rsoxs scans and spirals || for rsoxs scans, a more complex nomenclature is available to define exposures for certain energy ranges. See the notebook example or the wiki || 1 ||  \n",
      "|-\n",
      "| Acquisitions || temperatures || temperature(s) to move to between / during scans.  || repeat the scans above for each temperature. || 120 || ONLY used with the TEM holder - not valid for normal sample bar\n",
      "|-\n",
      "| Acquisitions || temp ramp speed || the temperature ramp speed deg C / min ||  0.1 - 100 are valid speeds || 10 ||  \n",
      "|-\n",
      "| Acquisitions || wait at temperature || wait for the temperature to reach the setpoint before starting the scans or not || True/False || True ||  \n",
      "|-\n",
      "| Acquisitions || grating || which grating to use for measurements  || rsoxs (default), 1200, 250 || rsoxs || WARNING - moving gratings between measurements might result in loss of energy calibration\n",
      "|-\n",
      "| Acquisitions || diode_range || high or low range for diode measurements || high, low || high || high should be used in any case where saturation might be a possibility - the majority of measurements\n",
      "|}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example Output see: https://wiki-nsls2.bnl.gov/beamline7ID1/index.php?title=User:Bijal\n",
    "\n",
    "# Bar only\n",
    "#print(convertSampleSheetExcelMediaWiki(excelSheetInputPath, verbose=True, paramsSheetToOutput='Bar'))\n",
    "\n",
    "# Acquisitions only\n",
    "print(convertSampleSheetExcelMediaWiki(excelSheetInputPath, verbose=False, paramsSheetToOutput='Acquisitions'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85402741-6cc4-48cc-b70b-2a1066c8cf24",
   "metadata": {},
   "source": [
    "# Test Code during development of this function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbac10d0-51e2-4bdd-be8e-b59701dc2ed4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convertSampleSheetExcelMediaWiki2(\n",
    "    excelSheet: Path = None,\n",
    "    paramsSheetToOutput: str = \"all\",\n",
    "    rulesSheetName: str = \"SheetRulesAndMetaData\",\n",
    "    versionCell: str = \"B4\",\n",
    "    startRow_Params: int = 7,\n",
    "    endRow_Params: int = None,\n",
    "    startColumn_Params: str = \"A\",\n",
    "    endColumn_Params: str = \"F\",\n",
    ") -> str:\n",
    "    \"\"\"Converts Sample Sheet Parameter Metadata into a MediaWiki-compatible format string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    excelSheet: Path\n",
    "        Path (or string) to the excel sheet to be loaded.\n",
    "    rulesSheetName: str\n",
    "        Name of the excel sheet which should be parsed for metadata\n",
    "    paramsSheetToOutput: str\n",
    "        Which set of params should be output (e.g., 'bar', 'acquisitions'). 'all' will sequentially output tables for each sheet\n",
    "    versionCell: str\n",
    "        Location (e.g., 'B4') of the cell that contains the sheet version number\n",
    "    startRow_Params: int\n",
    "        Excel row number which contains the header for the metadata table (excel starts at row 1)\n",
    "    endRow_Params: int\n",
    "        Excel row number which contains the last row of metadata (leave as -1 if scanning to end of file)\n",
    "    startColumn_Params: str\n",
    "        First excel column (by letter) that contains the metadata table\n",
    "    endColumn_Params:str\n",
    "        Last excel column (by letter) that contains the metadata table\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A string containing the formatted table ready to copy-paste into MediaWiki\n",
    "    \"\"\"\n",
    "    # Split versionCell in (row, column)\n",
    "    versRow, versColumn = [\n",
    "        int(\"\".join(filter(str.isdigit, versionCell))),\n",
    "        \"\".join(filter(str.isalpha, versionCell)),\n",
    "    ]\n",
    "\n",
    "    # Extract Version Code as a string\n",
    "    versionStr = pd.read_excel(\n",
    "        excelSheet,\n",
    "        sheet_name=rulesSheetName,\n",
    "        index_col=None,\n",
    "        usecols=versColumn,\n",
    "        nrows=0,\n",
    "        header=versRow - 1,\n",
    "    )\n",
    "    versionStr = versionStr.columns.values[0]\n",
    "    # print(versionStr)\n",
    "\n",
    "    # Get Current Date\n",
    "    date.today()\n",
    "\n",
    "    # Add Wiki Page Header to Output string\n",
    "    outStr = (\n",
    "        f\"== SST-1 Sample Sheet Syntax Version: {versionStr} Last Updated: {date.today()} ==\\n\"\n",
    "    )\n",
    "\n",
    "    # Extract Metadata Table\n",
    "\n",
    "    # If endRow_Params is provided, limit the number of rows parsed\n",
    "    if endRow_Params is None:\n",
    "        numRows = None\n",
    "    else:\n",
    "        numRows = endRow_Params - startRow_Params\n",
    "\n",
    "    # Convert column bounds to string\n",
    "    colString = startColumn_Params + \":\" + endColumn_Params\n",
    "\n",
    "    excelMetadataIn = pd.read_excel(\n",
    "        excelSheet,\n",
    "        sheet_name=rulesSheetName,\n",
    "        header=startRow_Params - 1,\n",
    "        nrows=numRows,\n",
    "        usecols=colString,\n",
    "    )\n",
    "\n",
    "    # Replace NaNs and 'nan's with blank\n",
    "    excelMetadataIn = excelMetadataIn.replace(\"nan\", \"\")\n",
    "    excelMetadataIn = excelMetadataIn.fillna(\"\")\n",
    "    # display(excelMetadataIn)\n",
    "\n",
    "    # Construct MediaWiki Table\n",
    "    outStr += \"\\n\" + r'{| class=\"wikitable sortable\"' + \"\\n\" + \"|-\\n\"\n",
    "\n",
    "    # Add header row elements\n",
    "    outStr += \"! \"\n",
    "    for colHeader in excelMetadataIn.columns:\n",
    "        filteredColHeader = str(colHeader).replace(\"\\r\", \" \").replace(\"\\n\", \" \")\n",
    "        outStr += f\"{filteredColHeader} !! \"\n",
    "\n",
    "    # trim extra \"!! \"\n",
    "    outStr = outStr[:-4]\n",
    "\n",
    "    # Add Metadata Row Elements\n",
    "\n",
    "    ## Loop through metadata rows\n",
    "    for mdRow in excelMetadataIn.index - 1:\n",
    "        ###Loop through columns\n",
    "        outStr += \"\\n|-\\n| \"\n",
    "        for mdVal in excelMetadataIn.iloc[mdRow].to_list():\n",
    "            filteredmdVal = str(mdVal).replace(\"\\r\", \" \").replace(\"\\n\", \" \")\n",
    "            outStr += f\"{filteredmdVal} || \"\n",
    "            pass\n",
    "            # print(str(mdVal) + \"\\n\")\n",
    "\n",
    "    # Add MediaWiki Table End\n",
    "    outStr += \"\\n|}\"\n",
    "    # print(outStr)\n",
    "\n",
    "    return outStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "662fa040-d243-42c2-9d2a-c1aebd26d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "excelSheet = excelSheetInputPath\n",
    "rulesSheetName = \"SheetRulesAndMetaData\"\n",
    "versionCell = \"B4\"\n",
    "startRow_Params = 7\n",
    "endRow_Params = None\n",
    "startColumn_Params = \"A\"\n",
    "endColumn_Params = \"F\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d1f6295-4540-4fb2-9984-5eba80a67c2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Passed header=[3], len of 1, but only 1 lines in file (sheet: SheetRulesAndMetaData)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\bbp\\AppData\\Local\\mambaforge\\envs\\BP_PyHyperStable\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:709\u001b[0m, in \u001b[0;36mPythonParser._next_line\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 709\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_comments([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpos]])[\u001b[39m0\u001b[39m]\n\u001b[0;32m    710\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\bbp\\AppData\\Local\\mambaforge\\envs\\BP_PyHyperStable\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:400\u001b[0m, in \u001b[0;36mPythonParser._infer_columns\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mline_pos \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m hr:\n\u001b[1;32m--> 400\u001b[0m         line \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_line()\n\u001b[0;32m    402\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\bbp\\AppData\\Local\\mambaforge\\envs\\BP_PyHyperStable\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:722\u001b[0m, in \u001b[0;36mPythonParser._next_line\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n\u001b[1;32m--> 722\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[0;32m    723\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mStopIteration\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m versRow, versColumn \u001b[39m=\u001b[39m [\n\u001b[0;32m      3\u001b[0m     \u001b[39mint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mfilter\u001b[39m(\u001b[39mstr\u001b[39m\u001b[39m.\u001b[39misdigit, versionCell))),\n\u001b[0;32m      4\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mfilter\u001b[39m(\u001b[39mstr\u001b[39m\u001b[39m.\u001b[39misalpha, versionCell)),\n\u001b[0;32m      5\u001b[0m ]\n\u001b[0;32m      7\u001b[0m \u001b[39m# Extract Version Code as a string\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m versionStr \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_excel(\n\u001b[0;32m      9\u001b[0m     excelSheet,\n\u001b[0;32m     10\u001b[0m     sheet_name\u001b[39m=\u001b[39;49mrulesSheetName,\n\u001b[0;32m     11\u001b[0m     index_col\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     12\u001b[0m     usecols\u001b[39m=\u001b[39;49mversColumn,\n\u001b[0;32m     13\u001b[0m     nrows\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m     14\u001b[0m     header\u001b[39m=\u001b[39;49mversRow \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     16\u001b[0m versionStr \u001b[39m=\u001b[39m versionStr\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m]\n\u001b[0;32m     17\u001b[0m \u001b[39m# print(versionStr)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bbp\\AppData\\Local\\mambaforge\\envs\\BP_PyHyperStable\\lib\\site-packages\\pandas\\io\\excel\\_base.py:486\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    480\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m     )\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     data \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39;49mparse(\n\u001b[0;32m    487\u001b[0m         sheet_name\u001b[39m=\u001b[39;49msheet_name,\n\u001b[0;32m    488\u001b[0m         header\u001b[39m=\u001b[39;49mheader,\n\u001b[0;32m    489\u001b[0m         names\u001b[39m=\u001b[39;49mnames,\n\u001b[0;32m    490\u001b[0m         index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[0;32m    491\u001b[0m         usecols\u001b[39m=\u001b[39;49musecols,\n\u001b[0;32m    492\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    493\u001b[0m         converters\u001b[39m=\u001b[39;49mconverters,\n\u001b[0;32m    494\u001b[0m         true_values\u001b[39m=\u001b[39;49mtrue_values,\n\u001b[0;32m    495\u001b[0m         false_values\u001b[39m=\u001b[39;49mfalse_values,\n\u001b[0;32m    496\u001b[0m         skiprows\u001b[39m=\u001b[39;49mskiprows,\n\u001b[0;32m    497\u001b[0m         nrows\u001b[39m=\u001b[39;49mnrows,\n\u001b[0;32m    498\u001b[0m         na_values\u001b[39m=\u001b[39;49mna_values,\n\u001b[0;32m    499\u001b[0m         keep_default_na\u001b[39m=\u001b[39;49mkeep_default_na,\n\u001b[0;32m    500\u001b[0m         na_filter\u001b[39m=\u001b[39;49mna_filter,\n\u001b[0;32m    501\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    502\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[0;32m    503\u001b[0m         date_parser\u001b[39m=\u001b[39;49mdate_parser,\n\u001b[0;32m    504\u001b[0m         date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m    505\u001b[0m         thousands\u001b[39m=\u001b[39;49mthousands,\n\u001b[0;32m    506\u001b[0m         decimal\u001b[39m=\u001b[39;49mdecimal,\n\u001b[0;32m    507\u001b[0m         comment\u001b[39m=\u001b[39;49mcomment,\n\u001b[0;32m    508\u001b[0m         skipfooter\u001b[39m=\u001b[39;49mskipfooter,\n\u001b[0;32m    509\u001b[0m         dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[0;32m    510\u001b[0m     )\n\u001b[0;32m    511\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    512\u001b[0m     \u001b[39m# make sure to close opened file handles\u001b[39;00m\n\u001b[0;32m    513\u001b[0m     \u001b[39mif\u001b[39;00m should_close:\n",
      "File \u001b[1;32mc:\\Users\\bbp\\AppData\\Local\\mambaforge\\envs\\BP_PyHyperStable\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1551\u001b[0m, in \u001b[0;36mExcelFile.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, date_format, thousands, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[0;32m   1518\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse\u001b[39m(\n\u001b[0;32m   1519\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1520\u001b[0m     sheet_name: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mint\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1538\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds,\n\u001b[0;32m   1539\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, DataFrame] \u001b[39m|\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mint\u001b[39m, DataFrame]:\n\u001b[0;32m   1540\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1541\u001b[0m \u001b[39m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1542\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1549\u001b[0m \u001b[39m        DataFrame from the passed in Excel file.\u001b[39;00m\n\u001b[0;32m   1550\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39mparse(\n\u001b[0;32m   1552\u001b[0m         sheet_name\u001b[39m=\u001b[39msheet_name,\n\u001b[0;32m   1553\u001b[0m         header\u001b[39m=\u001b[39mheader,\n\u001b[0;32m   1554\u001b[0m         names\u001b[39m=\u001b[39mnames,\n\u001b[0;32m   1555\u001b[0m         index_col\u001b[39m=\u001b[39mindex_col,\n\u001b[0;32m   1556\u001b[0m         usecols\u001b[39m=\u001b[39musecols,\n\u001b[0;32m   1557\u001b[0m         converters\u001b[39m=\u001b[39mconverters,\n\u001b[0;32m   1558\u001b[0m         true_values\u001b[39m=\u001b[39mtrue_values,\n\u001b[0;32m   1559\u001b[0m         false_values\u001b[39m=\u001b[39mfalse_values,\n\u001b[0;32m   1560\u001b[0m         skiprows\u001b[39m=\u001b[39mskiprows,\n\u001b[0;32m   1561\u001b[0m         nrows\u001b[39m=\u001b[39mnrows,\n\u001b[0;32m   1562\u001b[0m         na_values\u001b[39m=\u001b[39mna_values,\n\u001b[0;32m   1563\u001b[0m         parse_dates\u001b[39m=\u001b[39mparse_dates,\n\u001b[0;32m   1564\u001b[0m         date_parser\u001b[39m=\u001b[39mdate_parser,\n\u001b[0;32m   1565\u001b[0m         date_format\u001b[39m=\u001b[39mdate_format,\n\u001b[0;32m   1566\u001b[0m         thousands\u001b[39m=\u001b[39mthousands,\n\u001b[0;32m   1567\u001b[0m         comment\u001b[39m=\u001b[39mcomment,\n\u001b[0;32m   1568\u001b[0m         skipfooter\u001b[39m=\u001b[39mskipfooter,\n\u001b[0;32m   1569\u001b[0m         dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m   1570\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds,\n\u001b[0;32m   1571\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bbp\\AppData\\Local\\mambaforge\\envs\\BP_PyHyperStable\\lib\\site-packages\\pandas\\io\\excel\\_base.py:889\u001b[0m, in \u001b[0;36mBaseExcelReader.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    888\u001b[0m         err\u001b[39m.\u001b[39margs \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00merr\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m (sheet: \u001b[39m\u001b[39m{\u001b[39;00masheetname\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39merr\u001b[39m.\u001b[39margs[\u001b[39m1\u001b[39m:])\n\u001b[1;32m--> 889\u001b[0m         \u001b[39mraise\u001b[39;00m err\n\u001b[0;32m    891\u001b[0m \u001b[39mif\u001b[39;00m last_sheetname \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    892\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mSheet name is an empty list\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bbp\\AppData\\Local\\mambaforge\\envs\\BP_PyHyperStable\\lib\\site-packages\\pandas\\io\\excel\\_base.py:851\u001b[0m, in \u001b[0;36mBaseExcelReader.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[39m# GH 12292 : error when read one empty column from excel file\u001b[39;00m\n\u001b[0;32m    850\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 851\u001b[0m     parser \u001b[39m=\u001b[39m TextParser(\n\u001b[0;32m    852\u001b[0m         data,\n\u001b[0;32m    853\u001b[0m         names\u001b[39m=\u001b[39mnames,\n\u001b[0;32m    854\u001b[0m         header\u001b[39m=\u001b[39mheader,\n\u001b[0;32m    855\u001b[0m         index_col\u001b[39m=\u001b[39mindex_col,\n\u001b[0;32m    856\u001b[0m         has_index_names\u001b[39m=\u001b[39mhas_index_names,\n\u001b[0;32m    857\u001b[0m         dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m    858\u001b[0m         true_values\u001b[39m=\u001b[39mtrue_values,\n\u001b[0;32m    859\u001b[0m         false_values\u001b[39m=\u001b[39mfalse_values,\n\u001b[0;32m    860\u001b[0m         skiprows\u001b[39m=\u001b[39mskiprows,\n\u001b[0;32m    861\u001b[0m         nrows\u001b[39m=\u001b[39mnrows,\n\u001b[0;32m    862\u001b[0m         na_values\u001b[39m=\u001b[39mna_values,\n\u001b[0;32m    863\u001b[0m         skip_blank_lines\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,  \u001b[39m# GH 39808\u001b[39;00m\n\u001b[0;32m    864\u001b[0m         parse_dates\u001b[39m=\u001b[39mparse_dates,\n\u001b[0;32m    865\u001b[0m         date_parser\u001b[39m=\u001b[39mdate_parser,\n\u001b[0;32m    866\u001b[0m         date_format\u001b[39m=\u001b[39mdate_format,\n\u001b[0;32m    867\u001b[0m         thousands\u001b[39m=\u001b[39mthousands,\n\u001b[0;32m    868\u001b[0m         decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m    869\u001b[0m         comment\u001b[39m=\u001b[39mcomment,\n\u001b[0;32m    870\u001b[0m         skipfooter\u001b[39m=\u001b[39mskipfooter,\n\u001b[0;32m    871\u001b[0m         usecols\u001b[39m=\u001b[39musecols,\n\u001b[0;32m    872\u001b[0m         dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    873\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds,\n\u001b[0;32m    874\u001b[0m     )\n\u001b[0;32m    876\u001b[0m     output[asheetname] \u001b[39m=\u001b[39m parser\u001b[39m.\u001b[39mread(nrows\u001b[39m=\u001b[39mnrows)\n\u001b[0;32m    878\u001b[0m     \u001b[39mif\u001b[39;00m header_names:\n",
      "File \u001b[1;32mc:\\Users\\bbp\\AppData\\Local\\mambaforge\\envs\\BP_PyHyperStable\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1803\u001b[0m, in \u001b[0;36mTextParser\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m   1748\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1749\u001b[0m \u001b[39mConverts lists of lists/tuples into DataFrames with proper type inference\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[39mand optional (e.g. string to datetime) conversion. Also enables iterating\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1800\u001b[0m \u001b[39m    .. versionchanged:: 1.2\u001b[39;00m\n\u001b[0;32m   1801\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1802\u001b[0m kwds[\u001b[39m\"\u001b[39m\u001b[39mengine\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpython\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1803\u001b[0m \u001b[39mreturn\u001b[39;00m TextFileReader(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\bbp\\AppData\\Local\\mambaforge\\envs\\BP_PyHyperStable\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\bbp\\AppData\\Local\\mambaforge\\envs\\BP_PyHyperStable\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1679\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1676\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1678\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1679\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions)\n\u001b[0;32m   1680\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1681\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\bbp\\AppData\\Local\\mambaforge\\envs\\BP_PyHyperStable\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:124\u001b[0m, in \u001b[0;36mPythonParser.__init__\u001b[1;34m(self, f, **kwds)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_col_indices: \u001b[39mlist\u001b[39m[\u001b[39mint\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    119\u001b[0m columns: \u001b[39mlist\u001b[39m[\u001b[39mlist\u001b[39m[Scalar \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m]]\n\u001b[0;32m    120\u001b[0m (\n\u001b[0;32m    121\u001b[0m     columns,\n\u001b[0;32m    122\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_original_columns,\n\u001b[0;32m    123\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols,\n\u001b[1;32m--> 124\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infer_columns()\n\u001b[0;32m    126\u001b[0m \u001b[39m# Now self.columns has the set of columns that we will process.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[39m# The original set is stored in self.original_columns.\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[39m# error: Cannot determine type of 'index_names'\u001b[39;00m\n\u001b[0;32m    129\u001b[0m (\n\u001b[0;32m    130\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns,\n\u001b[0;32m    131\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex_names,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex_names,  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    137\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\bbp\\AppData\\Local\\mambaforge\\envs\\BP_PyHyperStable\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:410\u001b[0m, in \u001b[0;36mPythonParser._infer_columns\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    408\u001b[0m     joi \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mstr\u001b[39m, header[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m have_mi_columns \u001b[39melse\u001b[39;00m header))\n\u001b[0;32m    409\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(joi)\u001b[39m}\u001b[39;00m\u001b[39m], len of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(joi)\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 410\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    411\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPassed header=\u001b[39m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut only \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mline_pos\u001b[39m}\u001b[39;00m\u001b[39m lines in file\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \u001b[39m# We have an empty file, so check\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[39m# if columns are provided. That will\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[39m# serve as the 'line' for parsing\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[39mif\u001b[39;00m have_mi_columns \u001b[39mand\u001b[39;00m hr \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Passed header=[3], len of 1, but only 1 lines in file (sheet: SheetRulesAndMetaData)"
     ]
    }
   ],
   "source": [
    "# Split versionCell in (row, column)\n",
    "versRow, versColumn = [\n",
    "    int(\"\".join(filter(str.isdigit, versionCell))),\n",
    "    \"\".join(filter(str.isalpha, versionCell)),\n",
    "]\n",
    "\n",
    "# Extract Version Code as a string\n",
    "versionStr = pd.read_excel(\n",
    "    excelSheet,\n",
    "    sheet_name=rulesSheetName,\n",
    "    index_col=None,\n",
    "    usecols=versColumn,\n",
    "    nrows=0,\n",
    "    header=versRow - 1,\n",
    ")\n",
    "versionStr = versionStr.columns.values[0]\n",
    "# print(versionStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4ccd2f3-9056-4539-8425-ec1634054c9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (1516084869.py, line 53)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[17], line 53\u001b[1;36m\u001b[0m\n\u001b[1;33m    return outStr\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "# Extract Metadata Table\n",
    "\n",
    "# If endRow_Params is provided, limit the number of rows parsed\n",
    "if endRow_Params is None:\n",
    "    numRows = None\n",
    "else:\n",
    "    numRows = endRow_Params - startRow_Params\n",
    "\n",
    "# Convert column bounds to string\n",
    "colString = startColumn_Params + \":\" + endColumn_Params\n",
    "\n",
    "excelMetadataIn = pd.read_excel(\n",
    "    excelSheet,\n",
    "    sheet_name=rulesSheetName,\n",
    "    header=startRow_Params - 1,\n",
    "    nrows=numRows,\n",
    "    usecols=colString,\n",
    ")\n",
    "\n",
    "# Replace NaNs and 'nan's with blank\n",
    "excelMetadataIn = excelMetadataIn.replace(\"nan\", \"\")\n",
    "excelMetadataIn = excelMetadataIn.fillna(\"\")\n",
    "# display(excelMetadataIn)\n",
    "\n",
    "# Construct MediaWiki Table\n",
    "outStr = r'{| class=\"wikitable sortable\"' + \"\\n\" + \"|-\\n\"\n",
    "\n",
    "# Add header row elements\n",
    "outStr += \"! \"\n",
    "for colHeader in excelMetadataIn.columns:\n",
    "    filteredColHeader = str(colHeader).replace(\"\\r\", \" \").replace(\"\\n\", \" \")\n",
    "    outStr += f\"{filteredColHeader} !! \"\n",
    "\n",
    "# trim extra \"!! \"\n",
    "outStr = outStr[:-4]\n",
    "\n",
    "# Add Metadata Row Elements\n",
    "\n",
    "## Loop through metadata rows\n",
    "for mdRow in excelMetadataIn.index - 1:\n",
    "    ###Loop through columns\n",
    "    outStr += \"\\n|-\\n| \"\n",
    "    for mdVal in excelMetadataIn.iloc[mdRow].to_list():\n",
    "        filteredmdVal = str(mdVal).replace(\"\\r\", \" \").replace(\"\\n\", \" \")\n",
    "        outStr += f\"{filteredmdVal} || \"\n",
    "        pass\n",
    "        # print(str(mdVal) + \"\\n\")\n",
    "\n",
    "# Add MediaWiki Table End\n",
    "outStr += \"\\n|}\"\n",
    "# print(outStr)\n",
    "\n",
    "return outStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dc8b4f-499c-4b67-a670-b382f4c85b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "excelDataIn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beamline-stuff",
   "language": "python",
   "name": "beamline-stuff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "054bedd935cc4fb30a8577dfc7551b971df042c2fe48c0ba637d4f4d7d65a122"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
